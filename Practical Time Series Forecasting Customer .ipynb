{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Trend Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Forecasting Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfivethirtyeight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Customers_in_a_Shop.csv',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Date','Customers']\n",
    "data['Date'] = pd.to_datetime(data['Date'],format=\"%Y-%m\")\n",
    "data = data.set_index('Date')\n",
    "\n",
    "#Shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data Handling in Time Series\n",
    "### We have the following methods for treating missing values in the time series data.\n",
    "1)\tMean Imputation\n",
    "\n",
    "2)\tLast Observation Carried forward\n",
    "\n",
    "3)\tLinear Interpolation\n",
    "\n",
    "4)\tSeasonal Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "\n",
    "plt.plot(data,color='black')\n",
    "plt.title(\"Customers in a Shop since 1949\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "data['Customers_mean'] = data['Customers'].fillna(data['Customers'].mean())\n",
    "plt.plot(data['Customers_mean'],color='black')\n",
    "plt.title(\"Mean Imputation of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Fill Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "\n",
    "data['Customers_bfill'] = data['Customers'].bfill()\n",
    "\n",
    "plt.plot(data['Customers_bfill'],color='black')\n",
    "plt.title(\"Last Observation Carried Forward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "\n",
    "data['Customers_linear']=data['Customers'].interpolate(method='linear')\n",
    "\n",
    "plt.plot(data['Customers_linear'],color='black')\n",
    "plt.title(\"Linear Interpolation of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the dates where we have missing values\n",
    "data.index[data['Customers'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example for 1960 take average seasonal of previous date\n",
    "data['1949-03':'1959-03':12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1949-03':'1959-03':12].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1949-03':'1959-03':12].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1949-03':'1959-03':12].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['1960-03'].fillna((data['1949-03':'1959-03':12].sum())/data['1949-03':'1959-03':12].shape[0], inplace=True)\n",
    "data.loc['1954-06'].fillna((data['1949-06':'1953-06':12].sum())/data['1949-06':'1953-06':12].shape[0], inplace=True)\n",
    "data.loc['1951-07'].fillna((data['1949-07':'1950-07':12].sum())/data.loc['1949-07':'1950-07':12].shape[0], inplace=True)\n",
    "data.loc['1951-06'].fillna((data['1949-06':'1950-06':12].sum())/data['1949-06':'1950-06':12].shape[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "plt.plot(data['Customers'],color='black')\n",
    "plt.title(\"Seasonal Interpolation of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Treatment in Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "sns.boxplot(data['Customers_linear'], color='brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Customers_linear'].sort_values(ascending = False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers treatment\n",
    "\n",
    "data['Customers_linear'].loc[(data['Customers_linear']>=700)] = 622\n",
    "# lets also check the null values again\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(17,5)\n",
    "sns.boxplot(data['Customers_linear'], color='brown')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(data['Customers_linear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import pylab \n",
    "scipy.stats.probplot(data['Customers_linear'],plot=pylab)\n",
    "pylab.show()\n",
    "\n",
    "# Y-Axis: Data Value\n",
    "# X-Axis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for correct statistic Analysis you can use Zscore function from statsmodels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Decomposition\n",
    "### Additive Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,8)\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(data['Customers_linear'], model='additive')\n",
    "decomposition.plot()\n",
    "                                          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Be attention at Y-Scale in Seasonal! (-50,+50) from orginal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "plt.rcParams['figure.figsize'] = (17,8)\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(data['Customers_linear'], model='multiplicative')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"Customers_linear\"])*0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We Split the data into train and test.\n",
    "* First 115 rows as the train data and rest other as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Customers'] = data['Customers_linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train = 115\n",
    "train = data.iloc[:length_train,:]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=data.iloc[length_train:,: ]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Method\n",
    "The naive method is the simplest method of all forecasting methods. It looks at the last historical data and extrapolates it for all the future values without adjusting or attempting to establish causal factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Customers\"][113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Customers\"][114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Customers\"][115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = test.copy()\n",
    "y_naive['forecasted_naive'] = train.Customers[length_train-1]\n",
    "y_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,5)\n",
    "\n",
    "plt.plot(train['Customers'], label = 'Train')\n",
    "plt.plot(test['Customers'], label = 'Test')\n",
    "plt.plot(y_naive['forecasted_naive'], label = 'naive forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Naive Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Average Method\n",
    "In this method, we take the future predictions equal to the average of all the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = test.copy()\n",
    "\n",
    "y_avg['forecasted_avg'] = train['Customers'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,5)\n",
    "\n",
    "plt.plot(train['Customers'], label = 'Train')\n",
    "plt.plot(test['Customers'], label = 'Test')\n",
    "plt.plot(y_avg['forecasted_avg'], label = 'simple average forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Simple Average Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Moving Average Method\n",
    "In this method, we take the future predictions equal to the average of a moving window. A window can be a time period of 3 months, 6 months, 9 months or 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_moving = data.copy()\n",
    "\n",
    "window = 9\n",
    "y_moving[\"moving_average_forecast\"] = data['Customers'].rolling(window).mean()\n",
    "# y_moving['moving_average_forecast'][length_train:] = y_moving['moving_average_forecast'][length_train-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,5)\n",
    "\n",
    "plt.plot(train['Customers'], label = 'Train')\n",
    "plt.plot(test['Customers'], label = 'Test')\n",
    "plt.plot(y_moving['moving_average_forecast'], label = 'simple moving average forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Simple moving Average Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* are you serious about using it for time series modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Exponential Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "ins2 = SimpleExpSmoothing(train['Customers']).fit(smoothing_level=0.8,optimized=False)\n",
    "ins_cast2 = ins2.forecast(3).rename('alpha=0.8')\n",
    "\n",
    "\n",
    "#Plot for alpha = 0.8\n",
    "ax = train['Customers'].plot(marker='o', color='black', figsize=(12,8), legend=True)\n",
    "ins_cast2.plot(marker='o', ax=ax, color='red', legend=True)\n",
    "ins2.fittedvalues.plot(marker='o', ax=ax, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "#First Instance\n",
    "ins1 = SimpleExpSmoothing(train['Customers']).fit(smoothing_level=0.2,optimized=False)\n",
    "ins_cast1 = ins1.forecast(3).rename('alpha=0.2')\n",
    "\n",
    "#Second Instance\n",
    "ins2 = SimpleExpSmoothing(train['Customers']).fit(smoothing_level=0.8,optimized=False)\n",
    "ins_cast2 = ins2.forecast(3).rename('alpha=0.8')\n",
    "\n",
    "#Third Instance\n",
    "ins3 = SimpleExpSmoothing(train['Customers']).fit()\n",
    "ins_cast3 = ins3.forecast(3).rename('alpha=%s'%ins3.model.params['smoothing_level'])\n",
    "\n",
    "\n",
    "#After creating model we will visualize the plot\n",
    "ax = train['Customers'].plot(marker='o', color='black', figsize=(12,8), legend=True)\n",
    "\n",
    "\n",
    "#Plot for alpha =0.2\n",
    "ins_cast1.plot(marker='+', ax=ax, color='blue', legend=[True])\n",
    "ins1.fittedvalues.plot(marker='+', ax=ax, color='blue')\n",
    "\n",
    "#Plot for alpha = 0.8\n",
    "ins_cast2.plot(marker='o', ax=ax, color='red', legend=True)\n",
    "ins2.fittedvalues.plot(marker='o', ax=ax, color='red')\n",
    "\n",
    "#Plot for alpha=Optimized by statsmodel\n",
    "ins_cast3.plot(marker='*', ax=ax, color='green', legend=True)\n",
    "ins3.fittedvalues.plot(marker='*', ax=ax, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "model = SimpleExpSmoothing(train['Customers'])\n",
    "model_fit = model.fit(smoothing_level=1)\n",
    "# model_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_exp = test.copy()\n",
    "y_exp['Exponential_forecast'] = model_fit.forecast(24)\n",
    "y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,5)\n",
    "\n",
    "plt.plot(train['Customers'], label = 'Train')\n",
    "plt.plot(test['Customers'], label = 'Test')\n",
    "plt.plot(y_exp['Exponential_forecast'], label = 'simple exponential forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Simple Exponential Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Last day for alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holt Exponential Smoothing\n",
    "Holt’s exponential smoothing captures the level and trend of time series in the forecast.\n",
    "\n",
    "The forecast equation is a function of both level and trend.\n",
    "\n",
    "y(t+1) = l(t) +b(t) \n",
    "\n",
    "Where l(t) is the level component and b(t) is the trend component.\n",
    "\n",
    "The trend component is calculated as shown\n",
    "\n",
    "b(t) = β(l(t) - l(t-1)) + (1-β)b(t-1) \n",
    "\n",
    "Here beta is the smoothing parameter for trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "model = ExponentialSmoothing(train['Customers'], seasonal_periods=12, trend='multiplicative')\n",
    "model_fit = model.fit(smoothing_level=0.2,smoothing_slope=0.04)\n",
    "model_fit.params\n",
    "y_holtexponential = test.copy()\n",
    "y_holtexponential['holtexponential_forecast'] = model_fit.forecast(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,5)\n",
    "\n",
    "plt.plot(train['Customers'], label = 'Train')\n",
    "plt.plot(test['Customers'], label = 'Test')\n",
    "plt.plot(y_holtexponential['holtexponential_forecast'], label = 'Holts exponential forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Holts exponential Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holt Winter Exponential Smoothing\n",
    "This techniques forecasts based on level, trend and seasonality.\n",
    "The forecast equation for this method includes seasonality.\n",
    "\t\n",
    "y(t+1) = l(t)+b(t)+s(t+1-m) \n",
    "Here m is the number of time a season repeats in a time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExponentialSmoothing(train['Customers'], seasonal_periods=12, trend='multiplicative', seasonal='additive')\n",
    "model_fit = model.fit(smoothing_level=0.2,smoothing_slope=0.04)\n",
    "model_fit.params\n",
    "y_holtwinter = test.copy()\n",
    "y_holtwinter['holtwinter_forecast'] = model_fit.forecast(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,5)\n",
    "\n",
    "plt.plot(train['Customers'], label = 'Train')\n",
    "plt.plot(test['Customers'], label = 'Test')\n",
    "plt.plot(y_holtwinter['holtwinter_forecast'], label = 'Holts Winters exponential forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Holts winters exponential Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity\n",
    "Stationarity means that the statistical properties of a process generating a time series do not change over time. The statistical properties are Mean, variance and covariance which are same irrespective of the time at which you observe them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.Customers.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dickey-Fuller (ADF) Test for Stationarity\n",
    "Augmented Dickey Fuller test (ADF Test) is a common statistical test used to test whether a given Time series is stationary or not. It is one of the most commonly used statistical test when it comes to analyzing the stationary of a series.\n",
    "* p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "* p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(data['Customers'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.stattools as sts\n",
    "sts.adfuller(data['Customers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(data['Customers'])\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'n_lags: {result[2]}')\n",
    "print(\"\")\n",
    "\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* p-value > 5% >>>>> H0 Accepted (Fails to Reject) >>>>> Series is non-stationary\n",
    "\n",
    "* The mean value is not stationary.\n",
    "* The variance is fluctating over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "print(f\"{today:%B %d, %Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and plotting acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(data['Customers'], ax=plt.gca(), lags=30)\n",
    "plt.show()\n",
    "\n",
    "# gca: get current axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test\n",
    "The Kwiatkowski–Phillips–Schmidt–Shin (KPSS) test figures out if a time series is stationary around a mean or linear trend, or is non-stationary due to a unit root. A stationary time series is one where statistical properties — like the mean and variance — are constant over time.\n",
    "\n",
    "For KPSS test,\n",
    "\n",
    "The Null Hypothesis : The series is stationary when p-value >0.05\n",
    "\n",
    "Alternate Hypothesis: The series is not stationary when p-value <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading kpss from statsmodel\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "result = kpss(data['Customers'])\n",
    "print(f'KPSS Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'num lags: {result[2]}')\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "for key, value in result[3].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* p-value < 5% >>>>> H0 Rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Stationary Series to Stationary Series\n",
    "There are two tools for converting a non-stationary series into a stationary series.\n",
    "\n",
    "**1) Differencing**\n",
    "\n",
    "Differencing tool is used to make the mean constant for a time series. That means it removes the trend from the series. \n",
    "\n",
    "**2) Transformation**\n",
    "\n",
    "\n",
    "The procedure is to find the optimal value of lambda between -5 and +5 to minimize the variance of the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Cox Transformation\n",
    "A Box Cox transformation is a way to transform non-normal dependent variables into a normal shape. Normality is an important assumption for many statistical techniques; if your data isn't normal, applying a Box-Cox means that you are able to run a broader number of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "data_boxcox = pd.Series(boxcox(data['Customers'],lmbda=0),index=data.index)\n",
    "plt.plot(data_boxcox, label=\"After Box Cox Transformation\")\n",
    "plt.legend()\n",
    "plt.title(\"Number of Customers Visiting in an Ice Cream Shop since 1950\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "fitted_data, fitted_lambda = stats.boxcox(data['Customers'])\n",
    "\n",
    "# print(fitted_data)\n",
    "print(fitted_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx  = stats.boxcox(data['Customers'])\n",
    "xx[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate non-normal data (exponential)\n",
    "original_data = np.random.exponential(size = 1000)\n",
    "\n",
    "# transform training data & save lambda value\n",
    "fitted_data, fitted_lambda = stats.boxcox(original_data)\n",
    "\n",
    "# creating axes to draw plots\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# plotting the original data(non-normal) and fitted data (normal)\n",
    "sns.distplot(original_data, hist = False, kde = True,kde_kws = {'shade': True, 'linewidth': 2},\n",
    "             label = \"Non-Normal\", color =\"green\", ax = ax[0])\n",
    "\n",
    "sns.distplot(fitted_data, hist = False, kde = True,kde_kws = {'shade': True, 'linewidth': 2},\n",
    "             label = \"Normal\", color =\"green\", ax = ax[1])\n",
    "\n",
    "plt.legend(loc = \"upper right\")\n",
    "\n",
    "# rescaling the subplots\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "print(f\"Lambda value used for Transformation: {fitted_lambda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing\n",
    "\n",
    "Differencing stabilises the mean of a time series by removing changes in the level of a time series, and therefore eliminating (or reducing) trend and seasonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boxcox_difference= pd.Series(data_boxcox - data_boxcox.shift(), index=data.index)\n",
    "data_boxcox_difference.dropna(inplace=True)\n",
    "\n",
    "plt.plot(data_boxcox_difference, label=\"After Box Cox Transformation and Differencing\")\n",
    "plt.legend()\n",
    "plt.title(\"Number of Customers Visisting in a Ice Cream Shop since 1950\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADF Test\n",
    "\n",
    "Checking stationary after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(data_boxcox_difference)\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'n_lags: {result[1]:.20f}')\n",
    "print(f'p-value: {result[1]:.20f}')\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Correleation Function (ACF)\n",
    "ACF is an (complete) auto-correlation function which gives us values of auto-correlation of any series with its lagged values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and plotting acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(data_boxcox_difference, ax=plt.gca(), lags=30)\n",
    "plt.show()\n",
    "\n",
    "# gca: get current axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,3,4,5th have significant correlation with future observations.\n",
    "\n",
    "Model equation would be:\n",
    "\n",
    "* y = β0 + β1*y(t-1) + β2*y(t-3) + β3*y(t-4) + β4*y(t-5)\n",
    "\n",
    "* y(t-1), y(t-3), y(t-4) and y(t-5) are the independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Auto Correleation Function (PACF)\n",
    "Partial autocorrelation function (PACF) gives the partial correlation of a stationary time series with its own lagged values, regressed the values of the time series at all shorter lags. It contrasts with the autocorrelation function, which does not control for other lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and plottin pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_pacf(data_boxcox_difference, ax=plt.gca(), lags=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train = 115\n",
    "\n",
    "train_data_boxcox = data_boxcox[:length_train]\n",
    "test_data_boxcox = data_boxcox[length_train:]\n",
    "\n",
    "# for NA\n",
    "train_data_boxcox_difference = data_boxcox_difference[:length_train-1]\n",
    "test_data_boxcox_difference = data_boxcox_difference[length_train-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Regressive Model\n",
    "Regressive model is forecasting the future observations as a **linear regression** of one or more past observations.\n",
    "\n",
    "* This model has a parameter called “p” which is the lag order\n",
    "\n",
    "*  is the maximum number of lags that we consider in order to forecast the future observations.\n",
    "\n",
    "Autoregressive model equation would be\n",
    "\n",
    "\n",
    "* y(t) = β0 + β1*y(t-1) + β2*y(t-3) + β3*y(t-4) + β4*y(t-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model_ar = ARIMA(train_data_boxcox_difference, order=(1,0,0))\n",
    "model_fit = model_ar.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lag = 4 and Regression on 4 Features (Samples)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to Original Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ar_new = data_boxcox_difference.copy()\n",
    "y_ar_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ar_new['ar_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                              data_boxcox_difference.index.max())\n",
    "\n",
    "y_ar_new['ar_forecast_boxcox'] = y_ar_new['ar_forecast_boxcox_difference'].cumsum()\n",
    "y_ar_new['ar_forecast_boxcox'] = y_ar_new['ar_forecast_boxcox'].add(data_boxcox[0]) #add data\n",
    "y_ar_new['ar_forecast'] = np.exp(y_ar_new['ar_forecast_boxcox']) #transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_ar_new['ar_forecast'][test.index.min():], label = 'AR model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Auto regressive model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* only Trend Detected (Not Seasonal!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average Method\n",
    "In Moving Average Model, we consider the past forecasted errors to forecast the future values.\n",
    "\n",
    "The moving average model has a parameter called “q” which is the size of the moving average window over which linear combinations of errors are calculated.\n",
    "\n",
    "The mathematical equation is:-\n",
    "\n",
    "y(t) = µ + φ(k)*ε(t-k)\n",
    "\n",
    "µ is the mean of the series\n",
    "\n",
    "ε(t-k) is the past forecasted value\n",
    "\n",
    "φ(k) is the weight associated with error value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model_ma = ARIMA(train_data_boxcox_difference, order=(0,0,7))\n",
    "model_fit = model_ma.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boxcox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to Original Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ma_new = data_boxcox_difference.copy()\n",
    "y_ma_new['ma_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                              data_boxcox_difference.index.max())\n",
    "\n",
    "y_ma_new['ma_forecast_boxcox'] = y_ma_new['ma_forecast_boxcox_difference'].cumsum()\n",
    "y_ma_new['ma_forecast_boxcox'] = y_ma_new['ma_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_ma_new['ma_forecast'] = np.exp(y_ma_new['ma_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForeCasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_ma_new['ma_forecast'][test.index.min():], label = 'MA model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moving Average regressive model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Regressive Moving Average Model (ARMA)\n",
    "ARMA Model combines both AR and MA model.\n",
    "\n",
    "It takes into account one or more past observations as well as the past errors.\n",
    "\n",
    "The ARMA model contains two parameters p and q\n",
    "\n",
    "p is the highest lag in the time series\n",
    "\n",
    "q is the number of past errors included\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model_arma = ARIMA(train_data_boxcox_difference, order=(1,0,5))\n",
    "model_fit = model_arma.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arma_new = data_boxcox_difference.copy()\n",
    "y_arma_new['arma_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                                  data_boxcox_difference.index.max())\n",
    "y_arma_new['arma_forecast_boxcox'] = y_arma_new['arma_forecast_boxcox_difference'].cumsum()\n",
    "y_arma_new['arma_forecast_boxcox'] = y_arma_new['arma_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_arma_new['arma_forecast'] = np.exp(y_arma_new['arma_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_arma_new['arma_forecast'][test.index.min():], label = 'ARMA model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Auto regressive Moving Average model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Regressive Integrated Moving Average Model (ARIMA)\n",
    "\n",
    "It transform the time series using Box Cox and then itself takes care of the differencing and remove the trend from the time series.\n",
    "\n",
    "We have three parameters to be used:-\n",
    "\n",
    "p is the highest lag in the model\n",
    "\n",
    "d is the degree of differencing to make the series stationary\n",
    "\n",
    "q is the number of past errors terms included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model = ARIMA(train_data_boxcox, order=(1,1,5))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arima_new = data_boxcox_difference.copy()\n",
    "y_arima_new['arima_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                                    data_boxcox_difference.index.max())\n",
    "y_arima_new['arima_forecast_boxcox'] = y_arima_new['arima_forecast_boxcox_difference'].cumsum()\n",
    "y_arima_new['arima_forecast_boxcox'] = y_arima_new['arima_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_arima_new['arima_forecast'] = np.exp(y_arima_new['arima_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_arima_new['arima_forecast'][test.index.min():], label = 'ARiMA model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Auto regressive Integrated Moving Average model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Auto Regressive Integrated Moving Average Model (SARIMA)\n",
    "\n",
    "SARIMA model brings all the features of ARIMA model along with the seasonality.\n",
    "\n",
    "The key elements performed in SARIMA are:-\n",
    "\n",
    "1. The time series is differenced to make it stationary.\n",
    "\n",
    "2. The SARIMA equation is a linear combination of past observations and past errors.\n",
    "\n",
    "3. Seasonal differencing is performed on the time series.\n",
    "\n",
    "4. SARIMA models future seasonality as a linear combination of past seasonality observations and past seasonality errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "model = SARIMAX(train_data_boxcox_difference, order=(1,1,1), seasonal_order=(1,1,1,6))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sarima_new = data_boxcox_difference.copy()\n",
    "y_sarima_new['sarima_forecast_boxcox_difference'] = model_fit.predict(data_boxcox_difference.index.min(),\n",
    "                                                                      data_boxcox_difference.index.max())\n",
    "y_sarima_new['sarima_forecast_boxcox'] = y_sarima_new['sarima_forecast_boxcox_difference'].cumsum()\n",
    "y_sarima_new['sarima_forecast_boxcox'] = y_sarima_new['sarima_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_sarima_new['sarima_forecast'] = np.exp(y_sarima_new['sarima_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "\n",
    "plt.plot(train['Customers_linear'], label = 'Train')\n",
    "plt.plot(test['Customers_linear'], label = 'Test')\n",
    "plt.plot(y_sarima_new['sarima_forecast'][test.index.min():], label = 'SARIMA model')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Seasonal Auto regressive Integrated Moving Average model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
